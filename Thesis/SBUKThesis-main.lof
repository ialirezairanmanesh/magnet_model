\vspace {-1.5cm}\textbf {عنوان}~\hfill \textbf {صفحه}\vskip 1mm \hrule height 1.5pt\vspace {.25cm}
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2-1}{\ignorespaces ساختار کلی یک شبکه عصبی کانولوشنی (CNN): ابتدا تصویر ورودی یا ماتریس ویژگی وارد شبکه می‌شود. در مرحله استخراج ویژگی، لایه‌های کانولوشنی و تجمعی به ترتیب ویژگی‌های محلی را استخراج و ابعاد داده را کاهش می‌دهند. سپس داده‌ها به یک بردار یک‌بعدی تبدیل شده (Flattening) و وارد لایه‌های کاملاً متصل می‌شوند تا فرایند طبقه‌بندی نهایی انجام گیرد. این ساختار باعث می‌شود شبکه بتواند به صورت خودکار و بدون نیاز به مهندسی ویژگی دستی، الگوهای پیچیده را شناسایی کند. برگرفته از \blx@tocontentsinit {0}\cite {Alsaleh2023}.}}{16}{figure.caption.6}%
\contentsline {figure}{\numberline {2-2}{\ignorespaces نمایی از یک مدل شبکه عصبی گرافی (GNN): ابتدا گراف ورودی (با ویژگی‌های اولیه گره‌ها و ساختار اتصالات) به مدل داده می‌شود. سپس در چندین بلوک GNN (لایه)، اطلاعات گره‌ها با تجمیع اطلاعات از همسایگان و به‌روزرسانی با استفاده از شبکه‌های عصبی کوچک، به‌طور مکرر پالایش می‌شود تا بازنمایی‌های غنی‌تری (گراف تبدیل‌شده) حاصل شود. در نهایت، این بازنمایی‌ها می‌توانند برای وظایف مختلف مانند طبقه‌بندی کل گراف (مثلاً بدافزار/سالم)، طبقه‌بندی گره‌ها (مثلاً شناسایی توابع مخرب) یا پیش‌بینی لبه‌ها استفاده شوند. برگرفته و بازطراحی‌شده بر اساس \blx@tocontentsinit {0}\cite {sanchez-lengeling2021a}.}}{18}{figure.caption.7}%
\contentsline {figure}{\numberline {2-3}{\ignorespaces ساختار کلی معماری ترنسفورمر شامل بخش کدگذار (Encoder) در سمت چپ و گشاینده (Decoder) در سمت راست. هر دو بخش از پشته‌ای از لایه‌های یکسان تشکیل شده‌اند که عمدتاً شامل مکانیزم توجه چندسر (Multi-Head Attention) و شبکه‌های عصبی پیش‌خور (Feed Forward) هستند. اتصالات باقیمانده (Add) و نرمال‌سازی لایه‌ای (Norm) نیز برای پایداری آموزش استفاده می‌شوند. گشاینده علاوه بر توجه خودی، از توجه متقابل (Cross-Attention) برای در نظر گرفتن خروجی کدگذار نیز بهره می‌برد. این معماری امکان پردازش موازی و مدل‌سازی وابستگی‌های بلندمدت را فراهم می‌کند. برگرفته و بازطراحی‌شده بر اساس \blx@tocontentsinit {0}\cite {attention}.}}{20}{figure.caption.8}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3-1}{\ignorespaces معماری مدل MAGNET شامل سه ماژول تخصصی (EnhancedTabTransformer، GraphTransformer، SequenceTransformer)، لایه ادغام چندوجهی و طبقه‌بند باینری.}}{39}{figure.caption.9}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4-1}{\ignorespaces نمایش موقعیت کشتی‌ها (Ships)، رهبر (Leader)، نقشه (Map)، کشتی‌های برتر (\lr {Top Ships}) و کشتی‌های غیرهمگرا (Un-Conv) در فضای جستجو.}}{49}{figure.caption.10}%
\contentsline {figure}{\numberline {4-2}{\ignorespaces روند تغییر بهترین مقدار هزینه (BSF)، میانگین هزینه (Average)، مقایسه BSF و Average و مسیر رهبر (Trajectory) در طول تکرارها.}}{50}{figure.caption.11}%
\contentsline {figure}{\numberline {4-3}{\ignorespaces تغییرات سرعت (Velocity)، باد (Wind)، نیروی محرکه (F) و شتاب (Acceleration) کشتی‌ها در طول تکرارها.}}{51}{figure.caption.12}%
\contentsline {figure}{\numberline {4-4}{\ignorespaces نتایج اعتبارسنجی متقاطع 5-تایی مدل MAGNET}}{55}{figure.caption.14}%
\contentsline {figure}{\numberline {4-5}{\ignorespaces مقایسه کلی عملکرد مدل MAGNET در مراحل مختلف. نمودار میله‌ای نشان‌دهنده مقادیر F1 Score، دقت و AUC در هر مرحله است.}}{56}{figure.caption.16}%
\contentsline {figure}{\numberline {4-6}{\ignorespaces مقایسه دقت مدل MAGNET با روش‌های چندوجهی و مبتنی بر ترنسفورمر. نمودار میله‌ای نشان‌دهنده مقادیر دقت برای هر روش است.}}{56}{figure.caption.18}%
\contentsline {figure}{\numberline {4-7}{\ignorespaces مقایسه \lr {F1 Score} و AUC مدل MAGNET با سایر مدل‌های یادگیری ماشین. نمودار میله‌ای نشان‌دهنده مقادیر هر معیار برای هر مدل است. نام دیتاست مربوط به هر مدل در زیر آن نمایش داده شده است.}}{57}{figure.caption.20}%
\contentsline {figure}{\numberline {4-8}{\ignorespaces عملکرد هر ماژول (EnhancedTabTransformer، GraphTransformer، SequenceTransformer) را با معیار \lr {F1 Score} نشان می‌دهد. محور افقی ماژول‌ها و محور عمودی مقدار \lr {F1 Score} را نمایش می‌دهد.}}{62}{figure.caption.21}%
\contentsline {figure}{\numberline {4-9}{\ignorespaces روند افزایش \lr {F1 Score} را با افزودن مکانیزم توجه پویا و لایه ادغام چندوجهی نمایش می‌دهد. محور افقی اجزای مدل (بدون توجه پویا، با توجه پویا، با ادغام چندوجهی) و محور عمودی مقدار \lr {F1 Score} را نشان می‌دهد.}}{62}{figure.caption.22}%
\contentsline {figure}{\numberline {4-10}{\ignorespaces تغییرات \lr {F1 Score} و دقت را در طول ۳ دوره آموزش با بهینه‌سازی بهینه‌سازی (اعتبارسنجی) نمایش می‌دهد. محور افقی شماره دوره‌ها و محور عمودی مقادیر \lr {F1 Score} و دقت را نشان می‌دهد.}}{63}{figure.caption.23}%
\addvspace {10\p@ }
\addvspace {10\p@ }
